{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeNode:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.cat_features = None\n",
    "\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.isleaf = False\n",
    "        \n",
    "        self.split_val = None\n",
    "        self.split_feature = None\n",
    "        self.classification = None\n",
    "        \n",
    "        self.depth = 0\n",
    "\n",
    "    def is_pure(self, y):\n",
    "        # check whether the branch is pure() having same class )\n",
    "        \n",
    "        # compare all class label with the class of first row. \n",
    "#         print(y)\n",
    "        for i in y:\n",
    "            if i != y[0]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def find_split_val(self, X, y):\n",
    "        # Find best split value\n",
    "        class_values = list(set(y))\n",
    "        b_feature, b_value, b_score, b_groups = None, None, None, None\n",
    "        for feature in range(len(X[0])):\n",
    "            for row in X:                \n",
    "                groups = self.split(feature, row[feature], X, y)\n",
    "                gini = self.gini_index([groups[0]['y'], groups[1]['y']], class_values)\n",
    "#                 print('X%d < %.3f Gini=%.3f' % ((feature + 1), row[feature], gini))\n",
    "                if b_score is None or gini < b_score:\n",
    "                    b_index, b_value, b_score, b_groups = feature, row[feature], gini, groups\n",
    "        return {'index': b_index, 'value': b_value, 'groups': b_groups, 'gini': b_score}\n",
    "\n",
    "    def split(self, feature, val, X, y):\n",
    "        # split data according to split criteria\n",
    "        left_X, left_y, right_X, right_y = list(), list(), list(), list()\n",
    "        if feature in self.cat_features:\n",
    "            # categorical feature\n",
    "            # data with feature value equal to val goes to left ( feature == val )\n",
    "            # the rest goes to right\n",
    "            for idx, row in enumerate(X):\n",
    "                if row[feature] == val:\n",
    "                    left_X.append(row)\n",
    "                    left_y.append(y[idx])\n",
    "                else:\n",
    "                    right_X.append(row) \n",
    "                    right_y.append(y[idx])\n",
    "        #             idx = X[feature] == val\n",
    "        #             left_X = X.loc[idx]\n",
    "        #             left_y = y.loc[idx]\n",
    "        #             idx = ~idx\n",
    "        #             right_X = X.loc[idx] \n",
    "        #             right_y = y.loc[idx] \n",
    "        else:\n",
    "            # numerical feature\n",
    "            # data with feature value smaller than val goes to left ( feature < val )\n",
    "            # the rest goes to right\n",
    "            for idx, row in enumerate(X):\n",
    "                if row[feature] < val:\n",
    "                    left_X.append(row)\n",
    "                    left_y.append(y[idx])\n",
    "                else:\n",
    "                    right_X.append(row) \n",
    "                    right_y.append(y[idx])\n",
    "\n",
    "\n",
    "        return [{'X':left_X, 'y':left_y}, {'X': right_X, 'y': right_y}]\n",
    "\n",
    "    def gini_index(self, groups, classes):\n",
    "        # calculte Gini index of a split\n",
    "        # sum up gini index i(s,t) of both children trees, ex. i_left + i_right\n",
    "\n",
    "        n_instances = 0\n",
    "\n",
    "        for gr in groups:\n",
    "            n_instances += len(gr)\n",
    "\n",
    "        # sum weighted Gini index for each group\n",
    "        gini = 0.0\n",
    "        for gr in groups:\n",
    "            size = len(gr)\n",
    "            # avoid divide by zero\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "\n",
    "            # score the group based on the score for each class\n",
    "            for class_val in classes:\n",
    "                p = 0.0\n",
    "                for v in gr:\n",
    "                    if v == class_val:\n",
    "                        p += 1\n",
    "                p = p/ size\n",
    "                score += p * p\n",
    "            # weight the group score by its relative size\n",
    "            gini += (1.0 - score) * (size / n_instances) # *0.5\n",
    "        return gini\n",
    "\n",
    "    def grow(self, X, y, max_depth, depth):\n",
    "        \n",
    "        if self.is_pure(y) or max_depth <= depth:\n",
    "#             print(\"terminate at depth={}\".format(depth))\n",
    "            self.terminate(y, depth)\n",
    "            return\n",
    "        else:\n",
    "            \n",
    "            best_split = self.find_split_val(X, y)\n",
    "            self.split_val = best_split['value']\n",
    "            self.split_feature = best_split['index']\n",
    "            [left, right] = best_split['groups']\n",
    "\n",
    "#             print(\"{}X{} < {} gini={}\".format(self.depth*' ',self.split_feature+1, self.split_val, best_split['gini']))\n",
    "#             print(\"left - Class 0:{},class 1:{}\".format(np.sum(left.iloc[:,-1]==0),np.sum(left.iloc[:,-1]==1)))\n",
    "#             print(\"right - Class 0:{},class 1:{}\".format(np.sum(right.iloc[:,-1]==0),np.sum(right.iloc[:,-1]==1)))\n",
    "            \n",
    "            self.left = DecisionTreeNode()\n",
    "            self.right = DecisionTreeNode()\n",
    "            self.left.cat_features = self.cat_features\n",
    "            self.right.cat_features = self.cat_features\n",
    "            self.left.grow(left['X'], left['y'], max_depth, depth+1)\n",
    "            self.right.grow(right['X'], right['y'], max_depth, depth+1)\n",
    "\n",
    "        self.depth = depth\n",
    "        return\n",
    "        \n",
    "    def terminate(self, y, depth):\n",
    "        # define leaf node\n",
    "        # most frequent class in the data as class label of this node\n",
    "        self.classification = max(set(y), key=y.count)\n",
    "        self.isleaf = True\n",
    "        self.depth = depth\n",
    "    \n",
    "    def train(self, X, y, cat_features, max_depth):\n",
    "        # grow a tree\n",
    "        self.cat_features = cat_features\n",
    "        X = X.values.tolist()\n",
    "        y = y.values.tolist()\n",
    "        self.grow(X, y, max_depth, 1)\n",
    "\n",
    "    def print_tree(self):\n",
    "        if not self.isleaf:\n",
    "            if self.split_feature in self.cat_features:\n",
    "                print(\"{}X{} = {} \".format(self.depth*' ',self.split_feature, self.split_val))\n",
    "            else:\n",
    "                print(\"{}X{} < {} \".format(self.depth*' ',self.split_feature, self.split_val))\n",
    "            self.left.print_tree()\n",
    "            self.right.print_tree()\n",
    "        else:\n",
    "            print(\"{}[{}]\".format(self.depth*' ', self.classification))\n",
    "        \n",
    "    def predict_iterate(self, row):\n",
    "        \n",
    "        if self.isleaf:\n",
    "            # is leaf node\n",
    "            return self.classification\n",
    "        else:\n",
    "            # not leaf node\n",
    "            if self.split_feature in self.cat_features:\n",
    "                # predict categorical feature \n",
    "                if row[self.split_feature] == self.split_val:\n",
    "                    return self.left.predict_iterate(row)\n",
    "                else:\n",
    "                    return self.right.predict_iterate(row)\n",
    "            else:\n",
    "                # predict numerical feature \n",
    "                if row[self.split_feature] < self.split_val:\n",
    "                    return self.left.predict_iterate(row)\n",
    "                else:\n",
    "                    return self.right.predict_iterate(row)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        num_rows = X.shape[0]\n",
    "        prediction = []\n",
    "#         prediction = np.zeros((num_rows,1))\n",
    "        for idx, row in X.iterrows():\n",
    "            prediction.append(self.predict_iterate(row))\n",
    "            \n",
    "        return np.array(prediction)\n",
    "\n",
    "    def prune(self, tree):\n",
    "        # prune here\n",
    "        pruned_tree = tree\n",
    "        return pruned_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame([[23.771244718,1.784783929, 'a',0],\n",
    "[66.728571309,55.169761413, 'a',0],\n",
    "[3.678319846,3.81281357, 'a',0],\n",
    "[3.961043357,0.61995032, 'a',0],\n",
    "[2.999208922,2.209014212, 'b',0],\n",
    "[7.497545867,3.162953546, 'b',1],\n",
    "[9.00220326,3.339047188, 'b',1],\n",
    "[7.444542326,0.476683375, 'b',1],\n",
    "[10.12493903,3.234550982, 'b',1],\n",
    "[6.642287351,3.319983761, 'b',1]])\n",
    "\n",
    "dt = DecisionTreeNode()\n",
    "dt.train(X=data.iloc[:,:-1],y=data.iloc[:,-1], cat_features=[2], max_depth=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X2 = a \n",
      "  [0]\n",
      "  X0 < 6.642287351 \n",
      "   [0]\n",
      "   [1]\n"
     ]
    }
   ],
   "source": [
    "dt.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = dt.predict(data)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Chronic Kidney Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'age'</th>\n",
       "      <th>'bp'</th>\n",
       "      <th>'sg'</th>\n",
       "      <th>'al'</th>\n",
       "      <th>'su'</th>\n",
       "      <th>'rbc'</th>\n",
       "      <th>'pc'</th>\n",
       "      <th>'pcc'</th>\n",
       "      <th>'ba'</th>\n",
       "      <th>'bgr'</th>\n",
       "      <th>...</th>\n",
       "      <th>'pcv'</th>\n",
       "      <th>'wbcc'</th>\n",
       "      <th>'rbcc'</th>\n",
       "      <th>'htn'</th>\n",
       "      <th>'dm'</th>\n",
       "      <th>'cad'</th>\n",
       "      <th>'appet'</th>\n",
       "      <th>'pe'</th>\n",
       "      <th>'ane'</th>\n",
       "      <th>'class'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   'age'  'bp'   'sg'  'al'  'su'   'rbc'      'pc'       'pcc'        'ba'  \\\n",
       "0   48.0  80.0  1.020   1.0   0.0     NaN    normal  notpresent  notpresent   \n",
       "1    7.0  50.0  1.020   4.0   0.0     NaN    normal  notpresent  notpresent   \n",
       "2   62.0  80.0  1.010   2.0   3.0  normal    normal  notpresent  notpresent   \n",
       "3   48.0  70.0  1.005   4.0   0.0  normal  abnormal     present  notpresent   \n",
       "4   51.0  80.0  1.010   2.0   0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "   'bgr'  ...  'pcv'  'wbcc'  'rbcc'  'htn'  'dm'  'cad'  'appet'  'pe' 'ane'  \\\n",
       "0  121.0  ...   44.0  7800.0     5.2    yes   yes     no     good    no    no   \n",
       "1    NaN  ...   38.0  6000.0     NaN     no    no     no     good    no    no   \n",
       "2  423.0  ...   31.0  7500.0     NaN     no   yes     no     poor    no   yes   \n",
       "3  117.0  ...   32.0  6700.0     3.9    yes    no     no     poor   yes   yes   \n",
       "4  106.0  ...   35.0  7300.0     4.6     no    no     no     good    no    no   \n",
       "\n",
       "  'class'  \n",
       "0     ckd  \n",
       "1     ckd  \n",
       "2     ckd  \n",
       "3     ckd  \n",
       "4     ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset/chronic_kidney_disease_full.csv\", na_values=['?','\\t?'])\n",
    "print(df.shape)\n",
    "df = df.drop(columns = ['id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill NA values with most frequent values in the column\n",
    "df = df.fillna(df.mode().iloc[0])\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical columns: ['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n",
      "\n",
      "categorical column index: [5, 6, 7, 8, 18, 19, 20, 21, 22, 23]\n",
      "\n",
      "numerical columns: ['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wbcc', 'rbcc']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_col = []\n",
    "for col in df.columns:\n",
    "    col = col.replace(\"'\",'')\n",
    "    new_col.append(col)\n",
    "df.columns = new_col\n",
    "\n",
    "str_cols = []\n",
    "str_cols_index = []\n",
    "num_cols = []\n",
    "i = 0\n",
    "for col in df.drop(columns = 'class').columns:\n",
    "    if df[col].dtype != np.int64 and df[col].dtype != np.float64:\n",
    "        str_cols.append(col)\n",
    "        str_cols_index.append(i)\n",
    "    else:\n",
    "        num_cols.append(col)\n",
    "    i += 1\n",
    "    \n",
    "print(\"categorical columns: {}\\n\".format(str_cols))\n",
    "print(\"categorical column index: {}\\n\".format(str_cols_index))\n",
    "print(\"numerical columns: {}\\n\".format(num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeNode()\n",
    "# %prun dt.train(X=X_train,y=y_train, cat_features=str_cols, max_depth=5)\n",
    "dt.train(X=X_train,y=y_train, cat_features=str_cols, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9696969696969697\n",
      " X11 < 1.3 \n",
      "  X2 < 1.02 \n",
      "   [ckd]\n",
      "   X3 < 1.0 \n",
      "    X14 < 13.2 \n",
      "     [ckd]\n",
      "     [notckd]\n",
      "    [ckd]\n",
      "  [ckd]\n"
     ]
    }
   ],
   "source": [
    "pred = dt.predict(X_test)\n",
    "\n",
    "print(np.sum(pred == y_test)/y_test.shape[0])\n",
    "dt.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test with GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This is a module to be used as a reference for building other modules\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "class DecisionTreeNode(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\" An example classifier\n",
    "    For more information regarding how to build your own classifier, read more\n",
    "    in the :ref:`User Guide <user_guide>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    demo_param : str, default='demo'\n",
    "        A parameter used for demonstation of how to pass and store paramters.\n",
    "    Attributes\n",
    "    ----------\n",
    "    X_ : ndarray, shape (n_samples, n_features)\n",
    "        The input passed during :meth:`fit`.\n",
    "    y_ : ndarray, shape (n_samples,)\n",
    "        The labels passed during :meth:`fit`.\n",
    "    classes_ : ndarray, shape (n_classes,)\n",
    "        The classes seen at :meth:`fit`.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth, cat_features=None):\n",
    "        #property\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        #constant\n",
    "        self.cat_features = cat_features\n",
    "        #variables\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.isleaf = False\n",
    "        \n",
    "        self.split_val = None\n",
    "        self.split_feature = None\n",
    "        self.classification = None\n",
    "        \n",
    "        self.depth = 0\n",
    "\n",
    "    def is_pure(self, y):\n",
    "        # check whether the branch is pure() having same class )\n",
    "        \n",
    "        # compare all class label with the class of first row. \n",
    "#         print(y)\n",
    "        for i in y:\n",
    "            if i != y[0]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def find_split_val(self, X, y):\n",
    "        # Find best split value\n",
    "        class_values = list(set(y))\n",
    "        b_feature, b_value, b_score, b_groups = None, None, None, None\n",
    "        for feature in range(len(X[0])):\n",
    "            for row in X:                \n",
    "                groups = self.split(feature, row[feature], X, y)\n",
    "                gini = self.gini_index([groups[0]['y'], groups[1]['y']], class_values)\n",
    "#                 print('X%d < %.3f Gini=%.3f' % ((feature + 1), row[feature], gini))\n",
    "                if b_score is None or gini < b_score:\n",
    "                    b_index, b_value, b_score, b_groups = feature, row[feature], gini, groups\n",
    "        return {'index': b_index, 'value': b_value, 'groups': b_groups, 'gini': b_score}\n",
    "\n",
    "    def split(self, feature, val, X, y):\n",
    "        # split data according to split criteria\n",
    "        left_X, left_y, right_X, right_y = list(), list(), list(), list()\n",
    "        if feature in self.cat_features:\n",
    "            # categorical feature\n",
    "            # data with feature value equal to val goes to left ( feature == val )\n",
    "            # the rest goes to right\n",
    "            for idx, row in enumerate(X):\n",
    "                if row[feature] == val:\n",
    "                    left_X.append(row)\n",
    "                    left_y.append(y[idx])\n",
    "                else:\n",
    "                    right_X.append(row) \n",
    "                    right_y.append(y[idx])\n",
    "        #             idx = X[feature] == val\n",
    "        #             left_X = X.loc[idx]\n",
    "        #             left_y = y.loc[idx]\n",
    "        #             idx = ~idx\n",
    "        #             right_X = X.loc[idx] \n",
    "        #             right_y = y.loc[idx] \n",
    "        else:\n",
    "            # numerical feature\n",
    "            # data with feature value smaller than val goes to left ( feature < val )\n",
    "            # the rest goes to right\n",
    "            for idx, row in enumerate(X):\n",
    "                if row[feature] < val:\n",
    "                    left_X.append(row)\n",
    "                    left_y.append(y[idx])\n",
    "                else:\n",
    "                    right_X.append(row) \n",
    "                    right_y.append(y[idx])\n",
    "\n",
    "\n",
    "        return [{'X':left_X, 'y':left_y}, {'X': right_X, 'y': right_y}]\n",
    "\n",
    "    def gini_index(self, groups, classes):\n",
    "        # calculte Gini index of a split\n",
    "        # sum up gini index i(s,t) of both children trees, ex. i_left + i_right\n",
    "\n",
    "        n_instances = 0\n",
    "\n",
    "        for gr in groups:\n",
    "            n_instances += len(gr)\n",
    "\n",
    "        # sum weighted Gini index for each group\n",
    "        gini = 0.0\n",
    "        for gr in groups:\n",
    "            size = len(gr)\n",
    "            # avoid divide by zero\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "\n",
    "            # score the group based on the score for each class\n",
    "            for class_val in classes:\n",
    "                p = 0.0\n",
    "                for v in gr:\n",
    "                    if v == class_val:\n",
    "                        p += 1\n",
    "                p = p/ size\n",
    "                score += p * p\n",
    "            # weight the group score by its relative size\n",
    "            gini += (1.0 - score) * (size / n_instances) # *0.5\n",
    "        return gini\n",
    "\n",
    "    def grow(self, X, y, depth):\n",
    "        \n",
    "        if self.is_pure(y) or self.max_depth <= depth:\n",
    "#             print(\"terminate at depth={}\".format(depth))\n",
    "            self.terminate(y, depth)\n",
    "            return\n",
    "        else:\n",
    "            \n",
    "            best_split = self.find_split_val(X, y)\n",
    "            self.split_val = best_split['value']\n",
    "            self.split_feature = best_split['index']\n",
    "            [left, right] = best_split['groups']\n",
    "\n",
    "#             print(\"{}X{} < {} gini={}\".format(self.depth*' ',self.split_feature+1, self.split_val, best_split['gini']))\n",
    "#             print(\"left - Class 0:{},class 1:{}\".format(np.sum(left.iloc[:,-1]==0),np.sum(left.iloc[:,-1]==1)))\n",
    "#             print(\"right - Class 0:{},class 1:{}\".format(np.sum(right.iloc[:,-1]==0),np.sum(right.iloc[:,-1]==1)))\n",
    "            \n",
    "            self.left = DecisionTreeNode(self.max_depth, self.cat_features)\n",
    "            self.right = DecisionTreeNode(self.max_depth, self.cat_features)\n",
    "            self.left.grow(left['X'], left['y'], depth+1)\n",
    "            self.right.grow(right['X'], right['y'], depth+1)\n",
    "\n",
    "        self.depth = depth\n",
    "        return\n",
    "        \n",
    "    def terminate(self, y, depth):\n",
    "        # define leaf node\n",
    "        # most frequent class in the data as class label of this node\n",
    "        self.classification = max(set(y), key=y.count)\n",
    "        self.isleaf = True\n",
    "        self.depth = depth\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # grow a tree\n",
    "        X = X.values.tolist()\n",
    "        y = y.values.tolist()\n",
    "        self.grow(X, y, 1)\n",
    "        return self\n",
    "\n",
    "    def print_tree(self):\n",
    "        if not self.isleaf:\n",
    "            if self.split_feature in self.cat_features:\n",
    "                print(\"{}X{} = {} \".format(self.depth*' ',self.split_feature, self.split_val))\n",
    "            else:\n",
    "                print(\"{}X{} < {} \".format(self.depth*' ',self.split_feature, self.split_val))\n",
    "            self.left.print_tree()\n",
    "            self.right.print_tree()\n",
    "        else:\n",
    "            print(\"{}[{}]\".format(self.depth*' ', self.classification))\n",
    "        \n",
    "    def predict_iterate(self, row):\n",
    "        \n",
    "        if self.isleaf:\n",
    "            # is leaf node\n",
    "            return self.classification\n",
    "        else:\n",
    "            # not leaf node\n",
    "            if self.split_feature in self.cat_features:\n",
    "                # predict categorical feature \n",
    "                if row[self.split_feature] == self.split_val:\n",
    "                    return self.left.predict_iterate(row)\n",
    "                else:\n",
    "                    return self.right.predict_iterate(row)\n",
    "            else:\n",
    "                # predict numerical feature \n",
    "                if row[self.split_feature] < self.split_val:\n",
    "                    return self.left.predict_iterate(row)\n",
    "                else:\n",
    "                    return self.right.predict_iterate(row)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        num_rows = X.shape[0]\n",
    "        prediction = []\n",
    "#         prediction = np.zeros((num_rows,1))\n",
    "        for idx, row in X.iterrows():\n",
    "            prediction.append(self.predict_iterate(row))\n",
    "            \n",
    "        return np.array(prediction)\n",
    "\n",
    "    def prune(self, tree):\n",
    "        # prune here\n",
    "        pruned_tree = tree\n",
    "        return pruned_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeNode(cat_features=['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane'],\n",
       "         max_depth=5)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeNode(max_depth=5, cat_features=str_cols)\n",
    "# %prun dt.train(X=X_train,y=y_train, cat_features=str_cols, max_depth=5)\n",
    "dt.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9696969696969697\n",
      " X11 < 1.3 \n",
      "  X2 < 1.02 \n",
      "   [ckd]\n",
      "   X3 < 1.0 \n",
      "    X14 < 13.2 \n",
      "     [ckd]\n",
      "     [notckd]\n",
      "    [ckd]\n",
      "  [ckd]\n"
     ]
    }
   ],
   "source": [
    "pred = dt.predict(X_test)\n",
    "\n",
    "print(np.sum(pred == y_test)/y_test.shape[0])\n",
    "dt.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daiwei Lin\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters={\"max_depth\": [1,3,4,5,6,8]}\n",
    "gridsearch = GridSearchCV(dt, parameters, cv=4, return_train_score=True)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "grid_search_result = pd.DataFrame(gridsearch.cv_results_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1}</td>\n",
       "      <td>0.632353</td>\n",
       "      <td>0.632353</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.634328</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>6</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.633663</td>\n",
       "      <td>0.634332</td>\n",
       "      <td>0.000668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.457853</td>\n",
       "      <td>0.042931</td>\n",
       "      <td>0.008254</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.034299</td>\n",
       "      <td>5</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.960396</td>\n",
       "      <td>0.965347</td>\n",
       "      <td>0.953936</td>\n",
       "      <td>0.016820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.543123</td>\n",
       "      <td>0.083795</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.955224</td>\n",
       "      <td>0.027332</td>\n",
       "      <td>4</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.985149</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.986312</td>\n",
       "      <td>0.004157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.617640</td>\n",
       "      <td>0.122783</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.962687</td>\n",
       "      <td>0.024217</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.995050</td>\n",
       "      <td>0.995050</td>\n",
       "      <td>0.996275</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.641645</td>\n",
       "      <td>0.110135</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966418</td>\n",
       "      <td>0.028186</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.644898</td>\n",
       "      <td>0.111336</td>\n",
       "      <td>0.009002</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966418</td>\n",
       "      <td>0.028186</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.001502      0.000498         0.006506        0.000863   \n",
       "1       0.457853      0.042931         0.008254        0.000432   \n",
       "2       0.543123      0.083795         0.008752        0.000829   \n",
       "3       0.617640      0.122783         0.009002        0.000707   \n",
       "4       0.641645      0.110135         0.009002        0.000707   \n",
       "5       0.644898      0.111336         0.009002        0.000707   \n",
       "\n",
       "  param_max_depth            params  split0_test_score  split1_test_score  \\\n",
       "0               1  {'max_depth': 1}           0.632353           0.632353   \n",
       "1               3  {'max_depth': 3}           0.882353           0.955882   \n",
       "2               4  {'max_depth': 4}           0.911765           0.955882   \n",
       "3               5  {'max_depth': 5}           0.926471           0.955882   \n",
       "4               6  {'max_depth': 6}           0.926471           0.955882   \n",
       "5               8  {'max_depth': 8}           0.926471           0.955882   \n",
       "\n",
       "   split2_test_score  split3_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.636364           0.636364         0.634328        0.002005   \n",
       "1           0.969697           0.954545         0.940299        0.034299   \n",
       "2           0.984848           0.969697         0.955224        0.027332   \n",
       "3           0.984848           0.984848         0.962687        0.024217   \n",
       "4           0.984848           1.000000         0.966418        0.028186   \n",
       "5           0.984848           1.000000         0.966418        0.028186   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                6               0.635               0.635   \n",
       "1                5               0.925               0.965   \n",
       "2                4               0.980               0.990   \n",
       "3                3               0.995               1.000   \n",
       "4                1               1.000               1.000   \n",
       "5                1               1.000               1.000   \n",
       "\n",
       "   split2_train_score  split3_train_score  mean_train_score  std_train_score  \n",
       "0            0.633663            0.633663          0.634332         0.000668  \n",
       "1            0.960396            0.965347          0.953936         0.016820  \n",
       "2            0.985149            0.990099          0.986312         0.004157  \n",
       "3            0.995050            0.995050          0.996275         0.002151  \n",
       "4            1.000000            1.000000          1.000000         0.000000  \n",
       "5            1.000000            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9664179104477612"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
