{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Email Spam Dataset Using CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "import pandas as pd  \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import collections\n",
    "from sklearn.tree import export_graphviz\n",
    "import seaborn as sns   \n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.gridspec as gridspec\n",
    "import timeit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from collections import Counter\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "p= psutil.Process(os.getpid())\n",
    "\n",
    "def print_mem():\n",
    "    print(\"The memory usage for CART is- {:.0f}MB\".format(p.memory_info().rss/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCSV(file):\n",
    "    \"\"\"Loads a CSV file and converts all floats and ints into basic datatypes.\"\"\"\n",
    "    def convertTypes(s):\n",
    "#         print(\"Hi\")\n",
    "        s = s.strip()\n",
    "        try:\n",
    "            return float(s) if '.' in s else int(s)\n",
    "        except ValueError:\n",
    "            return s\n",
    "\n",
    "    reader = csv.reader(open(file, 'rt'))\n",
    "    dcHeader = {}\n",
    "    if bHeader:\n",
    "#         print(\"Hiiii\")\n",
    "        lsHeader = next(reader)\n",
    "        print(\"Column name is\",lsHeader)\n",
    "        for i, szY in enumerate(lsHeader):\n",
    "            szCol = 'Column %d' % i\n",
    "            dcHeader[szCol] = str(szY)\n",
    "            print(\"something :\", szCol)\n",
    "    return dcHeader, [[convertTypes(item) for item in row] for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_csv(filename):\n",
    "#     file = open(filename, \"r\")\n",
    "#     lines = reader(file)\n",
    "#     dataset = list(lines)\n",
    "#     return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "#         print(column)\n",
    "        row[column] = float(row[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_split(dataset, n_folds):\n",
    "#     print(dataset)\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "#     print(dataset_copy)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "#         print(\"Dataset split is:\",dataset_split)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "#         print(\"\\nTest set is:\",test_set)\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "#         print(\"\\nThe Class set is:\",actual)\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(index, value, dtype, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if dtype == 'category':\n",
    "            if row[index] == value:\n",
    "                left.append(row)\n",
    "            else:\n",
    "                right.append(row)\n",
    "        else:\n",
    "            # countinueous\n",
    "            if row[index] < value:\n",
    "                left.append(row)\n",
    "            else:\n",
    "                right.append(row)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chi_square(groups, classes):\n",
    "    \n",
    "    # count all samples at split point\n",
    "    observed=[]\n",
    "#     n_instances = float(sum([len(group) for group in groups]))\n",
    "    # sum weighted Gini index for each group\n",
    "    \n",
    "    p_value=0.0\n",
    "    y = groups.iloc[:, -1]\n",
    "    a = y.loc[y == 1]\n",
    "    a1=len(a)\n",
    "    observed.append(a1)\n",
    "    b = y.loc[y == 0]\n",
    "    b1=len(b)\n",
    "    observed.append(b1)\n",
    "    observed\n",
    "    expected=(observed[0]+observed[1])/2\n",
    "    expected\n",
    "    result=chisquare(observed,expected)\n",
    "    p_value=result[1]\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(groups, classes):\n",
    "    # count all samples at split point\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    # sum weighted Gini index for each group\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        # avoid divide by zero\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        # score the group based on the score for each class\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        # weight the group score by its relative size\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(dataset, cat_features):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            if index in cat_features:\n",
    "                dtype = 'category'\n",
    "            else:\n",
    "                dtype = 'continuous'\n",
    "            groups = test_split(index, row[index], dtype, dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "#             gini = Chi_square(groups, class_values)\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(node, cat_features, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left, cat_features)\n",
    "        split(node['left'],cat_features, max_depth, min_size, depth+1)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right, cat_features)\n",
    "        split(node['right'],cat_features, max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(train, cat_features, max_depth, min_size):\n",
    "    root = get_split(train, cat_features)\n",
    "    split(root, cat_features, max_depth, min_size, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node, row):\n",
    "    \n",
    "    if type(node['value']) is float:\n",
    "        if row[node['index']] < node['value']:\n",
    "            if isinstance(node['left'], dict):\n",
    "                return predict(node['left'], row)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict):\n",
    "                return predict(node['right'], row)\n",
    "            else:\n",
    "                return node['right']\n",
    "    else:\n",
    "        if row[node['index']] == node['value']:\n",
    "            if isinstance(node['left'], dict):\n",
    "                return predict(node['left'], row)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict):\n",
    "                return predict(node['right'], row)\n",
    "            else:\n",
    "                return node['right']\n",
    "        \n",
    "# Print a decision tree\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        if type(node['value']) is float:\n",
    "            print('{}[X{:d} < {:.3f}]'.format(depth*' ', (node['index']+1), node['value']))\n",
    "        else:\n",
    "            print('{}[X{:d} = {}]'.format(depth*' ', (node['index']+1), node['value']))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(train, test, max_depth, min_size):\n",
    "    global tree\n",
    "    tree = build_tree(train, max_depth, min_size)\n",
    "    print(\"Tree is \",tree)\n",
    "    \n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        prediction = predict(tree, row)\n",
    "        predictions.append(prediction)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X3 = a]\n",
      " [X1 < 11.000]\n",
      "  [X1 < 8.700]\n",
      "   [0]\n",
      "   [0]\n",
      "  [0]\n",
      " [X1 < 7.498]\n",
      "  [X1 < 7.445]\n",
      "   [1]\n",
      "   [1]\n",
      "  [X1 < 7.498]\n",
      "   [1]\n",
      "   [1]\n",
      "{'index': 2, 'value': 'a', 'left': {'index': 0, 'value': 11.0, 'left': {'index': 0, 'value': 8.7, 'left': 0, 'right': 0}, 'right': 0}, 'right': {'index': 0, 'value': 7.497545867, 'left': {'index': 0, 'value': 7.444542326, 'left': 1, 'right': 1}, 'right': {'index': 0, 'value': 7.497545867, 'left': 1, 'right': 1}}}\n"
     ]
    }
   ],
   "source": [
    "dataset = [[11.0,1.784783929,'a',0],\n",
    "[8.7,1.169761413,'a',0],\n",
    "[3.678319846,2.81281357,'a',0],\n",
    "[3.961043357,2.61995032,'a',0],\n",
    "[2.999208922,2.209014212,'a',0],\n",
    "[7.497545867,3.162953546,'b',1],\n",
    "[9.00220326,3.339047188,'b',1],\n",
    "[7.444542326,0.476683375,'b',1],\n",
    "[10.12493903,3.234550982,'b',1],\n",
    "[6.642287351,3.319983761,'b',1]]\n",
    "tree = build_tree(dataset,[2], 3, 1)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=1, Got=1\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n"
     ]
    }
   ],
   "source": [
    "dataset = [[20,1.784783929,'b',1],\n",
    "[8.7,1.169761413,'a',0],\n",
    "[3.678319846,2.81281357,'a',0],\n",
    "[3.961043357,2.61995032,'a',0],\n",
    "[2.999208922,2.209014212,'a',0],\n",
    "[7.497545867,3.162953546,'b',1],\n",
    "[9.00220326,3.339047188,'b',1],\n",
    "[7.444542326,0.476683375,'b',1],\n",
    "[10.12493903,3.234550982,'b',1],\n",
    "[6.642287351,3.319983761,'b',1]]\n",
    "for row in dataset:\n",
    "    prediction = predict(tree, row)\n",
    "    print('Expected=%d, Got=%d' % (row[-1], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'age'</th>\n",
       "      <th>'bp'</th>\n",
       "      <th>'sg'</th>\n",
       "      <th>'al'</th>\n",
       "      <th>'su'</th>\n",
       "      <th>'rbc'</th>\n",
       "      <th>'pc'</th>\n",
       "      <th>'pcc'</th>\n",
       "      <th>'ba'</th>\n",
       "      <th>'bgr'</th>\n",
       "      <th>...</th>\n",
       "      <th>'pcv'</th>\n",
       "      <th>'wbcc'</th>\n",
       "      <th>'rbcc'</th>\n",
       "      <th>'htn'</th>\n",
       "      <th>'dm'</th>\n",
       "      <th>'cad'</th>\n",
       "      <th>'appet'</th>\n",
       "      <th>'pe'</th>\n",
       "      <th>'ane'</th>\n",
       "      <th>'class'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   'age'  'bp'   'sg'  'al'  'su'   'rbc'      'pc'       'pcc'        'ba'  \\\n",
       "0   48.0  80.0  1.020   1.0   0.0     NaN    normal  notpresent  notpresent   \n",
       "1    7.0  50.0  1.020   4.0   0.0     NaN    normal  notpresent  notpresent   \n",
       "2   62.0  80.0  1.010   2.0   3.0  normal    normal  notpresent  notpresent   \n",
       "3   48.0  70.0  1.005   4.0   0.0  normal  abnormal     present  notpresent   \n",
       "4   51.0  80.0  1.010   2.0   0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "   'bgr'  ...  'pcv'  'wbcc'  'rbcc'  'htn'  'dm'  'cad'  'appet'  'pe' 'ane'  \\\n",
       "0  121.0  ...   44.0  7800.0     5.2    yes   yes     no     good    no    no   \n",
       "1    NaN  ...   38.0  6000.0     NaN     no    no     no     good    no    no   \n",
       "2  423.0  ...   31.0  7500.0     NaN     no   yes     no     poor    no   yes   \n",
       "3  117.0  ...   32.0  6700.0     3.9    yes    no     no     poor   yes   yes   \n",
       "4  106.0  ...   35.0  7300.0     4.6     no    no     no     good    no    no   \n",
       "\n",
       "  'class'  \n",
       "0     ckd  \n",
       "1     ckd  \n",
       "2     ckd  \n",
       "3     ckd  \n",
       "4     ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset/chronic_kidney_disease_full.csv\", na_values=['?','\\t?'])\n",
    "print(df.shape)\n",
    "df = df.drop(columns = ['id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill NA values with most frequent values in the column\n",
    "df = df.fillna(df.mode().iloc[0])\n",
    "df.isnull().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical columns: ['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n",
      "\n",
      "categorical column index: [5, 6, 7, 8, 18, 19, 20, 21, 22, 23]\n",
      "\n",
      "numerical columns: ['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wbcc', 'rbcc']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_col = []\n",
    "for col in df.columns:\n",
    "    col = col.replace(\"'\",'')\n",
    "    new_col.append(col)\n",
    "df.columns = new_col\n",
    "\n",
    "str_cols = []\n",
    "str_cols_index = []\n",
    "num_cols = []\n",
    "i = 0\n",
    "for col in df.drop(columns = 'class').columns:\n",
    "    if df[col].dtype != np.int64 and df[col].dtype != np.float64:\n",
    "        str_cols.append(col)\n",
    "        str_cols_index.append(i)\n",
    "    else:\n",
    "        num_cols.append(col)\n",
    "    i += 1\n",
    "    \n",
    "print(\"categorical columns: {}\\n\".format(str_cols))\n",
    "print(\"categorical column index: {}\\n\".format(str_cols_index))\n",
    "print(\"numerical columns: {}\\n\".format(num_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "df.sample(frac=0.8).to_csv('./dataset/ckd_train.csv', index = False, header=False)\n",
    "( _ ,ckd_dataset) = loadCSV('./dataset/ckd_train.csv')\n",
    "print(len(ckd_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = build_tree(ckd_dataset , str_cols_index, 5, 1)\n",
    "\n",
    "\n",
    "df.sample(frac=0.98).to_csv('./dataset/ckd_test.csv', index = False, header=False)\n",
    "( _ ,ckd_dataset) = loadCSV('./dataset/ckd_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate = 1.2755102040816326%\n"
     ]
    }
   ],
   "source": [
    "# prediction = []\n",
    "# test = []\n",
    "error = 0\n",
    "for row in ckd_dataset:\n",
    "#     prediction.append(predict(tree, row))\n",
    "#     test.append(row[-1])\n",
    "    if row[-1] != predict(tree, row):\n",
    "        error += 1\n",
    "\n",
    "print(\"error rate = {}%\".format(100*error/len(ckd_dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
