{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0            0.00               0.64           0.64           0.0   \n",
       "1            0.21               0.28           0.50           0.0   \n",
       "2            0.06               0.00           0.71           0.0   \n",
       "3            0.00               0.00           0.00           0.0   \n",
       "4            0.00               0.00           0.00           0.0   \n",
       "\n",
       "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0           0.32            0.00              0.00                0.00   \n",
       "1           0.14            0.28              0.21                0.07   \n",
       "2           1.23            0.19              0.19                0.12   \n",
       "3           0.63            0.00              0.31                0.63   \n",
       "4           0.63            0.00              0.31                0.63   \n",
       "\n",
       "   word_freq_order  word_freq_mail  ...    char_freq_;  char_freq_(  \\\n",
       "0             0.00            0.00  ...           0.00        0.000   \n",
       "1             0.00            0.94  ...           0.00        0.132   \n",
       "2             0.64            0.25  ...           0.01        0.143   \n",
       "3             0.31            0.63  ...           0.00        0.137   \n",
       "4             0.31            0.63  ...           0.00        0.135   \n",
       "\n",
       "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0          0.0        0.778        0.000        0.000   \n",
       "1          0.0        0.372        0.180        0.048   \n",
       "2          0.0        0.276        0.184        0.010   \n",
       "3          0.0        0.137        0.000        0.000   \n",
       "4          0.0        0.135        0.000        0.000   \n",
       "\n",
       "   capital_run_length_average  capital_run_length_longest  \\\n",
       "0                       3.756                          61   \n",
       "1                       5.114                         101   \n",
       "2                       9.821                         485   \n",
       "3                       3.537                          40   \n",
       "4                       3.537                          40   \n",
       "\n",
       "   capital_run_length_total  Class  \n",
       "0                       278      1  \n",
       "1                      1028      1  \n",
       "2                      2259      1  \n",
       "3                       191      1  \n",
       "4                       191      1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data = pd.read_csv(\"./dataset/spambase.data\", header=None)\n",
    "# add column names to spam_data \n",
    "spam_names = pd.read_csv('./dataset/spambase.names',sep=':',header=None)\n",
    "names = spam_names[0].tolist()\n",
    "names.append(\"Class\")\n",
    "print(len(names))\n",
    "\n",
    "spam_data.columns = names\n",
    "spam_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460, 58)\n"
     ]
    }
   ],
   "source": [
    "spam_data_sampled = spam_data.sample(frac=0.1)\n",
    "print(spam_data_sampled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data With Rules 0.9130434782608695\n",
      "f1_score of Test Data With Rules 0.8823529411764706\n",
      "recall_score of Test Data With Rules 0.8333333333333334\n",
      "before pruning: 436\n",
      "before pruning: 252\n",
      "Number of Rules after pruning 36\n",
      "Accuracy of Test Data With Rules 0.7934782608695652\n",
      "f1_score of Test Data With Rules 0.7076923076923076\n",
      "recall_score of Test Data With Rules 0.6388888888888888\n",
      "before pruning: 328\n",
      "before pruning: 173\n",
      "Number of Rules after pruning 30\n",
      "Accuracy of Test Data With Rules 0.8043478260869565\n",
      "f1_score of Test Data With Rules 0.7567567567567567\n",
      "recall_score of Test Data With Rules 0.8235294117647058\n",
      "before pruning: 324\n",
      "before pruning: 194\n",
      "Number of Rules after pruning 31\n",
      "Accuracy of Test Data With Rules 0.8913043478260869\n",
      "f1_score of Test Data With Rules 0.8571428571428571\n",
      "recall_score of Test Data With Rules 0.8823529411764706\n",
      "before pruning: 423\n",
      "before pruning: 236\n",
      "Number of Rules after pruning 37\n",
      "Accuracy of Test Data With Rules 0.8369565217391305\n",
      "f1_score of Test Data With Rules 0.7887323943661971\n",
      "recall_score of Test Data With Rules 0.8235294117647058\n",
      "before pruning: 536\n",
      "before pruning: 311\n",
      "Number of Rules after pruning 39\n",
      "Accuracy of Test Data With Rules 0.8913043478260869\n",
      "f1_score of Test Data With Rules 0.8000000000000002\n",
      "recall_score of Test Data With Rules 0.8\n",
      "before pruning: 332\n",
      "before pruning: 176\n",
      "Number of Rules after pruning 32\n",
      "Accuracy of Test Data With Rules 0.7608695652173914\n",
      "f1_score of Test Data With Rules 0.7027027027027026\n",
      "recall_score of Test Data With Rules 0.8125\n",
      "before pruning: 622\n",
      "before pruning: 398\n",
      "Number of Rules after pruning 39\n",
      "Accuracy of Test Data With Rules 0.8152173913043478\n",
      "f1_score of Test Data With Rules 0.8131868131868132\n",
      "recall_score of Test Data With Rules 0.8222222222222222\n",
      "before pruning: 445\n",
      "before pruning: 254\n",
      "Number of Rules after pruning 36\n",
      "Accuracy of Test Data With Rules 0.8586956521739131\n",
      "f1_score of Test Data With Rules 0.8219178082191781\n",
      "recall_score of Test Data With Rules 0.8333333333333334\n",
      "before pruning: 453\n",
      "before pruning: 311\n",
      "Number of Rules after pruning 34\n",
      "Accuracy of Test Data With Rules 0.8695652173913043\n",
      "f1_score of Test Data With Rules 0.8125000000000001\n",
      "recall_score of Test Data With Rules 0.7222222222222222\n",
      "before pruning: 299\n",
      "before pruning: 175\n",
      "Number of Rules after pruning 29\n",
      "Mean Accuracy So Far on Test: 0.47173913043478255\n",
      "The Mean Accuracy of Classifier 0.8434782608695652\n",
      "The Mean Variance of Classifier 0.002202268431001888\n",
      "Mean f1_score So Far on Test: 0.7942984581243283\n",
      "Mean recall_score So Far on Test: 0.7991911764705881\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "parent_node = None\n",
    "# the node class that will make up the tree\n",
    "class decisionTreeNode():\n",
    "    def __init__(self, is_leaf_node, classification, attribute_split_value, parent, left_child, right_child, height):\n",
    "\n",
    "        self.classification = None\n",
    "        self.attribute_split = None\n",
    "        self.attribute_split_value = None\n",
    "        self.parent = parent\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        self.height = None\n",
    "        self.is_leaf_node = True\n",
    "\n",
    "\n",
    "\n",
    "#Split the data based on the feature and a value to data above and data below\n",
    "def split_data(data, split_column, split_value):\n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    data_below = data[split_column_values <= split_value]\n",
    "    data_above = data[split_column_values >  split_value]\n",
    "    \n",
    "    return data_below, data_above\n",
    "\n",
    "#Get all the boundary values for each features (Key is feature and values are the splits)\n",
    "def get_potential_splits(data):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range(n_columns - 1):        # excluding the last column which is the label\n",
    "        potential_splits[column_index] = []\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "\n",
    "        for index in range(len(unique_values)):\n",
    "            if index != 0:\n",
    "                current_value = unique_values[index]\n",
    "                previous_value = unique_values[index - 1]\n",
    "                potential_split = (current_value + previous_value) / 2\n",
    "                \n",
    "                potential_splits[column_index].append(potential_split)\n",
    "        if (unique_values.shape[0] == 1):\n",
    "            potential_split = unique_values[index]\n",
    "            \n",
    "            potential_splits[column_index].append(potential_split)\n",
    "\n",
    "    \n",
    "    return potential_splits\n",
    "\n",
    "#Calculates Entropy of the data given\n",
    "def calculate_entropy(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "     \n",
    "    return entropy\n",
    "\n",
    "#Calculates the entropy of data below and data above\n",
    "def calculate_overall_entropy(data_below, data_above):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_entropy =  (p_data_below * calculate_entropy(data_below) \n",
    "                      + p_data_above * calculate_entropy(data_above))\n",
    "    \n",
    "    return overall_entropy\n",
    "\n",
    "#Check if all data is of same class\n",
    "def check_purity(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#Classify data based on majority\n",
    "def classify_data(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification\n",
    "\n",
    "#Gives the best feature and its split value after checking all features based on gain ratio\n",
    "def determine_best_split(data, potential_splits):\n",
    "    \n",
    "    entropy_label = calculate_entropy(data)   \n",
    "    overall_gain = -1.0\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "            current_information_gain = entropy_label - current_overall_entropy\n",
    "            current_splitting_info = splitting_information(data_below,data_above)\n",
    "            if current_splitting_info == 0:\n",
    "                current_gain_ratio = 0\n",
    "            else:\n",
    "                current_gain_ratio = float(current_information_gain / current_splitting_info)\n",
    "\n",
    "            if current_gain_ratio >= overall_gain:\n",
    "                overall_gain = current_gain_ratio\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value\n",
    "\n",
    "#Calculates the splitting Info of data above and below for that boundary value\n",
    "def splitting_information(data_below,data_above):\n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below)/ n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    if p_data_below == 0:\n",
    "        splitting_info = p_data_above * np.log2(p_data_above)\n",
    "    elif p_data_above == 0:\n",
    "        splitting_info = p_data_below * np.log2(p_data_below)\n",
    "    else:\n",
    "        splitting_info = -p_data_below * np.log2(p_data_below) -p_data_above * np.log2(p_data_above) \n",
    "    \n",
    "    return splitting_info\n",
    "\n",
    "def decision_tree_algorithm(df, parent_node,counter=0, min_samples=3):\n",
    "    node = decisionTreeNode(True, None, None, parent_node, None, None, 0)\n",
    "    # data preparations\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df           \n",
    "    \n",
    "    \n",
    "    # base cases\n",
    "    if (check_purity(data)) or (len(data) < min_samples):\n",
    "        classification = classify_data(data)\n",
    "        node.is_leaf_node = True\n",
    "        node.classification = classification\n",
    "        return node\n",
    "\n",
    "    \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1\n",
    "\n",
    "        # helper functions \n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        node.is_leaf_node = False\n",
    "        # instantiate sub-tree\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        \n",
    "        question = \"{} <= {}\".format(feature_name, split_value)\n",
    "\n",
    "\n",
    "       \n",
    "        if (parent_node == None):\n",
    "            node.height = 0\n",
    "        else:\n",
    "            node.parent = parent_node\n",
    "            node.height = node.parent.height + 1\n",
    "\n",
    "\n",
    "        node.attribute_split = feature_name\n",
    "        node.attribute_split_value = split_value\n",
    "\n",
    "        # find answers (recursion)\n",
    "        node.left_child = decision_tree_algorithm(data_below,node, counter, min_samples)\n",
    "        node.right_child = decision_tree_algorithm(data_above,node, counter, min_samples)\n",
    "        \n",
    "\n",
    "        return node\n",
    "\n",
    "def get_paths(root, path, pathlen,all_paths,val):\n",
    "    if (root==None):\n",
    "        return\n",
    "    \n",
    "    if root.is_leaf_node == True: \n",
    "        path.append(root.classification) \n",
    "    else:\n",
    "        path.append('row[\\'' + root.attribute_split + '\\']' + val + str(root.attribute_split_value))\n",
    "        \n",
    "    pathlen= pathlen+1\n",
    "    if (root.left_child == None and root.right_child == None): # If leaf, append current path\n",
    "        add = path[:]\n",
    "        all_paths.append(add)\n",
    "        path.pop()\n",
    "        root = root.parent\n",
    "    else:\n",
    "        get_paths(root.left_child, path, pathlen,all_paths,' <= ')\n",
    "        path[pathlen-1]= 'row[\\'' + root.attribute_split + '\\']' +' > ' + str(root.attribute_split_value)\n",
    "        get_paths(root.right_child, path,pathlen,all_paths,' <= ')\n",
    "        path.pop()\n",
    "\n",
    "    return all_paths\n",
    "\n",
    "def classify_test_data(root,data):\n",
    "    predictions = []\n",
    "    tree = root \n",
    "    data = data.iloc[:, :-1]\n",
    "    for index, sample in data.iterrows():\n",
    "        root = tree\n",
    "        while(tree.is_leaf_node!=True):\n",
    "            if (sample.loc[tree.attribute_split] <= tree.attribute_split_value):\n",
    "                tree = tree.left_child\n",
    "            else:\n",
    "                tree = tree.right_child\n",
    "        predictions.append(tree.classification)\n",
    "        tree = root\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def calc_accuracy_rule(rule,test):\n",
    "    wrong = 0\n",
    "#Check how many classified correctly\n",
    "    for index, row in test.iterrows():\n",
    "        s=0\n",
    "        while(s<len(rule)-1):\n",
    "            if (eval(rule[s])== False):\n",
    "                wrong += 1\n",
    "                break\n",
    "            s=s+1\n",
    "    #Initial Accuracy of one Rule before pruning\n",
    "    accuracy = (test.shape[0]-wrong) / test.shape[0]\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def recursive_len(item):\n",
    "    if type(item) == list:\n",
    "        return sum(recursive_len(subitem) for subitem in item)\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def prune(all_rules,val_data):\n",
    "    acc_rlist = []\n",
    "    maping = []\n",
    "    rulenos = []\n",
    "    #What are the labels in my val data\n",
    "    ctoprune = val_data['Class'].unique()\n",
    "#     Loop at all rules one by one\n",
    "    size_of_rules = recursive_len(all_rules)\n",
    "    print(\"before pruning:\",size_of_rules)\n",
    "    for i in range(len(all_rules)):\n",
    "        init_accuracy = 0\n",
    "        #Loop only on the rules applicable to my valset\n",
    "        if all_rules[i][-1] in ctoprune:\n",
    "                #Get the label of the Rule\n",
    "                label = all_rules[i][-1]\n",
    "                #Get all samples for that label\n",
    "                test = val_data[val_data['Class']==label]\n",
    "                #Check Initial Accuracy of the rule\n",
    "                init_accuracy = calc_accuracy_rule(all_rules[i],test)\n",
    "                print(\"initial_accuracy: {}\".format(init_accuracy))\n",
    "                \n",
    "                temp = all_rules[i][:]\n",
    "                pruned_accuracy = -1\n",
    "                while (init_accuracy!=pruned_accuracy):\n",
    "                # if (init_accuracy!=pruned_accuracy):\n",
    "                    for x in range(len(all_rules[i])-1):\n",
    "                        del temp[x]\n",
    "                        accuracy = calc_accuracy_rule(temp,test)\n",
    "                        if accuracy > init_accuracy:\n",
    "                            print(\"Better accuracy:{}\".format(accuracy))\n",
    "                            delx = x\n",
    "                            init_accuracy = accuracy\n",
    "                        temp = all_rules[i][:]\n",
    "                    # Ensure variable is defined\n",
    "                    try:\n",
    "                        delx\n",
    "                    except NameError:\n",
    "                        delx = None\n",
    "\n",
    "                    if delx is not None:\n",
    "                        del all_rules[i][delx]\n",
    "                        del delx\n",
    "                        # pruned_accuracy = init_accuracy\n",
    "                        if (len(all_rules[i])== 2):\n",
    "                            pruned_accuracy = init_accuracy\n",
    "                    else:\n",
    "                        pruned_accuracy = init_accuracy\n",
    "        else:\n",
    "            pruned_accuracy = init_accuracy\n",
    "        acc_rlist.append(pruned_accuracy)\n",
    "        rulenos.append(i)\n",
    "    maping.append(acc_rlist)\n",
    "    maping.append(rulenos)\n",
    "    size_of_rules = recursive_len(all_rules)\n",
    "    print(\"after pruning:\",size_of_rules)\n",
    "    maping= np.array(maping)\n",
    "    maping = pd.DataFrame(maping.T)\n",
    "    maping = maping.sort_values(0,ascending=False)\n",
    "    maping = pd.DataFrame(maping)\n",
    "    return all_rules,maping\n",
    "                \n",
    "def predict_prunedtree(all_rules,test_data,maping):\n",
    "    answer = []\n",
    "    unclassified = 0\n",
    "    for index, row in test_data.iterrows():\n",
    "        for indo,valus in maping.iterrows():\n",
    "            rule = all_rules[int(valus[1])]\n",
    "            s=0\n",
    "            count = 0\n",
    "            while(s<len(rule)-1):\n",
    "                if (eval(rule[s])== True):\n",
    "                    count = count + 1\n",
    "                s = s+1\n",
    "            if (count == len(rule)-1):\n",
    "                prediction = rule[-1]\n",
    "                break\n",
    "        try:\n",
    "            prediction\n",
    "        except NameError:\n",
    "            prediction = None\n",
    "        if prediction is not None:\n",
    "            answer.append(prediction)\n",
    "            del prediction\n",
    "        else:\n",
    "            unclassified = unclassified + 1\n",
    "#     print('Unclassified Sample',unclassified)\n",
    "    return answer\n",
    "\n",
    "def predict_preprunedtree(all_rules,test_data):\n",
    "    answer = []\n",
    "    unclassified = 0\n",
    "    for index, row in test_data.iterrows():\n",
    "        # prediction = row[-1]\n",
    "        for rule in all_rules:\n",
    "            s=0\n",
    "            count = 0\n",
    "            while(s<len(rule)-1):\n",
    "                if (eval(rule[s])== True):\n",
    "                    count = count + 1\n",
    "                s = s+1\n",
    "            if (count == len(rule)-1):\n",
    "                prediction = rule[-1]\n",
    "                break\n",
    "        try:\n",
    "            prediction\n",
    "        except NameError:\n",
    "            prediction = None\n",
    "        if prediction is not None:\n",
    "            answer.append(prediction)\n",
    "            del prediction\n",
    "        else:\n",
    "            unclassified = unclassified + 1\n",
    "#     print('Unclassified Sample',unclassified)\n",
    "    return answer\n",
    "\n",
    "def add_noise2(num,data):\n",
    "\n",
    "    siz_d = data.shape[0]\n",
    "    indx = int((num * siz_d)/100)\n",
    "    for x in range(indx):\n",
    "        pick = random.randint(0,int(siz_d/2))\n",
    "        label = data.iloc[pick:,-1].values[0]\n",
    "        if label > 0:\n",
    "            data.iloc[pick:,-1] = data.iloc[pick:,-1] - 1\n",
    "        else:\n",
    "            data.iloc[pick:,-1] = data.iloc[pick:,-1] + 1\n",
    "    return data\n",
    "\n",
    "def add_noise1(num,data):\n",
    "    siz_d = data.shape[0]\n",
    "    indx = int((num * siz_d)/100)\n",
    "    count = 0\n",
    "    for x in range(indx):\n",
    "        count = count+1\n",
    "        pick = random.randint(0,siz_d)\n",
    "        label = data.iloc[pick:,-1].values[0]\n",
    "        if label > 0:\n",
    "            label = label + 1\n",
    "        else:\n",
    "            label = label - 1\n",
    "        last = data.shape[0]  \n",
    "        data = data.append(data.iloc[pick,:])\n",
    "        data.iloc[last,-1] = label\n",
    "    return data\n",
    "\n",
    "noise1_5 = []\n",
    "noise1_10 = []\n",
    "noise1_15 = []\n",
    "noise2_5 = []\n",
    "noise2_10 = []\n",
    "noise2_15 = []\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    meanacc= []\n",
    "    meanf1_score= []\n",
    "    meanrecall_score= []\n",
    "    maping = []\n",
    "    mean_bprun = []\n",
    "    rkf = RepeatedKFold(n_splits=5, n_repeats=2, random_state=2652124)\n",
    "    for train_index, test_index in rkf.split(spam_data_sampled):\n",
    "        parent_node = None\n",
    "        test_data = spam_data_sampled.iloc[test_index]\n",
    "        train_data,val_data= train_test_split(spam_data_sampled.iloc[train_index], test_size=0.2)\n",
    "        \n",
    "        tree = decision_tree_algorithm(train_data,parent_node)\n",
    "        all_rules = get_paths(tree,[],0,[],' <= ')\n",
    "\n",
    "\n",
    "        \n",
    "# #         #Validation\n",
    "# #         y_true= val_data.iloc[:,-1].values\n",
    "# #         y_pred = classify_test_data(tree,val_data)\n",
    "# #         accuracy = accuracy_score(y_true, y_pred)\n",
    "# #         print('Pre-Pruning Accuracy of Val data With Just Tree',accuracy)\n",
    "        \n",
    "#         # # Pre-Pruning Accuracy of Test Data With Tree\n",
    "#         # y_true= test_data.iloc[:,-1].values\n",
    "#         # y_pred = classify_test_data(tree,test_data)\n",
    "#         # accuracy = accuracy_score(y_true, y_pred)\n",
    "#         # print('Pre-Pruning Accuracy of Test data With Just Tree',accuracy)\n",
    "        accuracy = []\n",
    "        #Pre-Pruning Accuracy of Test Data With Rules\n",
    "        y_true= test_data.iloc[:,-1].values\n",
    "        answer = predict_preprunedtree(all_rules,test_data)\n",
    "        accuracy = accuracy_score(y_true, answer)\n",
    "        f1_sc = f1_score(y_true, answer)\n",
    "        recall_sc = recall_score(y_true, answer)\n",
    "        print('Accuracy of Test Data With Rules',accuracy)\n",
    "        print('f1_score of Test Data With Rules',f1_sc)\n",
    "        print('recall_score of Test Data With Rules',recall_sc)\n",
    "        #print('Number of Rules before pruning',len(all_rules))\n",
    "        mean_bprun.append(accuracy)\n",
    "        #Post Pruning Accuracy with Rules\n",
    "        all_rules,maping = prune(all_rules,val_data)\n",
    "        print('Number of Rules after pruning',len(all_rules))\n",
    "        answer = predict_prunedtree(all_rules,test_data,maping)\n",
    "        # y_true= test_data.iloc[:,-1].values\n",
    "        accuracy = accuracy_score(y_true, answer)\n",
    "       # print('Post-Pruned Accuracy Without Noise',accuracy)\n",
    "        meanacc.append(accuracy)\n",
    "        meanf1_score.append(f1_sc)\n",
    "        meanrecall_score.append(recall_sc)\n",
    "\n",
    "        \n",
    "    print('Mean Accuracy So Far on Test:',sum(meanacc) / len(meanacc))\n",
    "    print('The Mean Accuracy of Classifier',sum(mean_bprun) / len(mean_bprun))\n",
    "    print('The Mean Variance of Classifier',np.var(np.array(mean_bprun)))\n",
    "    print('Mean f1_score So Far on Test:',sum(meanf1_score) / len(meanf1_score))\n",
    "    print('Mean recall_score So Far on Test:',sum(meanrecall_score) / len(meanrecall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
