{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class DecisionTreeC45Node:\n",
    "    def __init__(self, max_depth, cat_features=None):\n",
    "        # property\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "        # constant\n",
    "        self.cat_features = cat_features\n",
    "        # variables\n",
    "        self.children = list()\n",
    "        self.isleaf = False\n",
    "\n",
    "        self.split_val = None\n",
    "        self.split_feature = None\n",
    "        self.is_cat_feature = False\n",
    "        self.classification = None\n",
    "\n",
    "        self.depth = 0\n",
    "\n",
    "    def is_pure(self, y):\n",
    "        # check whether the branch is pure() having same class )\n",
    "\n",
    "        # compare all class label with the class of first row.\n",
    "        #         print(y)\n",
    "        for i in y:\n",
    "            if i != y[0]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def find_split_val(self, X, y, potential_features):\n",
    "        # Find best split value\n",
    "\n",
    "        class_values = list(set(y))     \n",
    "        b_feature, b_value, b_score, b_groups = None, None, None, None\n",
    "        \n",
    "        entropy_parent = self.entropy([y], class_values)\n",
    "        for feature in potential_features:\n",
    "            if feature in self.cat_features:\n",
    "                groups = self.split(feature, None, X, y)\n",
    "                groups_y = list()\n",
    "                split_values = list()\n",
    "                for v,gr in groups.items():\n",
    "                    groups_y.append(gr['y'])\n",
    "                    split_values.append(v)\n",
    "                entropy_children = self.entropy(groups_y, class_values)\n",
    "                split_info = self.splitting_information(groups_y)\n",
    "                if split_info == 0:\n",
    "                    gain_ratio = 0\n",
    "                else:\n",
    "                    gain_ratio = (entropy_parent - entropy_children)\n",
    "#                 print('X{:d} ={} E={:.3f},IG={:.3f},SI={:.3f},GR={:.3f}'.format((feature + 1), \n",
    "#                                                                                 split_values, \n",
    "#                                                                                 entropy_children, \n",
    "#                                                                                 (entropy_parent - entropy_children), \n",
    "#                                                                                 split_info, gain_ratio))\n",
    "                if b_score is None or gain_ratio > b_score:\n",
    "                    b_index, b_value, b_score, b_groups, is_cat_feature = feature, split_values, gain_ratio, groups, True\n",
    "            else:\n",
    "                for row in X:\n",
    "                    groups = self.split(feature, row[feature], X, y)\n",
    "                    groups_y = list()\n",
    "                    for _,gr in groups.items():\n",
    "                        groups_y.append(gr['y'])\n",
    "                    entropy_children = self.entropy(groups_y, class_values)\n",
    "                    split_info = self.splitting_information(groups_y)\n",
    "                    if split_info == 0:\n",
    "                        gain_ratio = 0\n",
    "                    else:\n",
    "                        gain_ratio = (entropy_parent - entropy_children)\n",
    "#                     print('X{:d} ={} E={:.3f},IG={:.3f},SI={:.3f},GR={:.3f}'.format((feature + 1), row[feature], entropy_children, (entropy_parent - entropy_children), split_info, gain_ratio))\n",
    "                    if b_score is None or gain_ratio > b_score:\n",
    "                        b_index, b_value, b_score, b_groups, is_cat_feature = feature, row[feature], gain_ratio, groups, False\n",
    "        return {'index': b_index, 'value': b_value, 'groups': b_groups, 'gain_ratio': b_score, 'is_cat_feature': is_cat_feature}\n",
    "\n",
    "    def split(self, feature, val, X, y):\n",
    "        # split data according to split criteria\n",
    "        groups = dict()\n",
    "        if feature in self.cat_features:\n",
    "            # categorical feature ( multiple branches )\n",
    "            # create branches for each category\n",
    "            for idx, row in enumerate(X):\n",
    "                if row[feature] in groups.keys():\n",
    "                    groups[row[feature]]['X'].append(row)\n",
    "                    groups[row[feature]]['y'].append(y[idx])\n",
    "                else:\n",
    "                    groups[row[feature]] = {'X': [row], 'y': [y[idx]]}\n",
    "        else:\n",
    "            # numerical feature (binary branches)\n",
    "            # data with feature value smaller than val goes to left ( feature < val )\n",
    "            # the rest goes to right\n",
    "            groups['left'] = {'X':list(), 'y':list()}\n",
    "            groups['right'] = {'X':list(), 'y':list()}\n",
    "            for idx, row in enumerate(X):\n",
    "                if row[feature] < val:\n",
    "                    groups['left']['X'].append(row)\n",
    "                    groups['left']['y'].append(y[idx])\n",
    "                else:\n",
    "                    groups['right']['X'].append(row)\n",
    "                    groups['right']['y'].append(y[idx])\n",
    "\n",
    "        return groups\n",
    "\n",
    "    def entropy(self, groups, classes):\n",
    "        # calculte entropy of a split\n",
    "        n_instances = 0\n",
    "        for gr in groups:\n",
    "            n_instances += len(gr)\n",
    "        \n",
    "        entropy = 0.0\n",
    "        for gr in groups:\n",
    "            size = len(gr)\n",
    "            # avoid divide by zero\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "\n",
    "            # score the group based on the score for each class\n",
    "            for class_val in classes:\n",
    "                p = 0.0\n",
    "                for v in gr:\n",
    "                    if v == class_val:\n",
    "                        p += 1\n",
    "                p = p / size\n",
    "                if p > 0:\n",
    "                    score += p * math.log2(p)\n",
    "            # weight the group score by its relative size\n",
    "            entropy += (score) * (size / n_instances)  # *0.5\n",
    "        entropy = -entropy\n",
    "        return entropy\n",
    "\n",
    "    def splitting_information(self, groups):\n",
    "        n_instances = 0\n",
    "        for gr in groups:\n",
    "            n_instances += len(gr)\n",
    "#             print(len(gr))\n",
    "        \n",
    "        splitting_info = 0.0\n",
    "        for gr in groups:\n",
    "            t = len(gr)/n_instances\n",
    "            if t > 0.0:\n",
    "                splitting_info += t * np.log2(t)\n",
    "        splitting_info = -splitting_info\n",
    "        return splitting_info\n",
    "\n",
    "    def grow(self, X, y, depth, potential_features):\n",
    "#         print(\"\\ndepth={}, p_features={}\".format(depth,potential_features))\n",
    "        if self.is_pure(y) or self.max_depth <= depth or len(potential_features) == 0:\n",
    "#             print(\"terminate at depth={}\".format(depth))\n",
    "            self.terminate(y, depth)\n",
    "            return\n",
    "        else:\n",
    "\n",
    "            best_split = self.find_split_val(X, y, potential_features)\n",
    "            self.split_val = best_split['value']\n",
    "            self.split_feature = best_split['index']\n",
    "            self.is_cat_feature = best_split['is_cat_feature']\n",
    "            print(\"split on feature:{} GR={}\".format(self.split_feature, best_split['gain_ratio']))\n",
    "            \n",
    "            if self.is_cat_feature:\n",
    "                potential_features.remove(self.split_feature)\n",
    "            for _, gr in best_split['groups'].items():\n",
    "                node = DecisionTreeC45Node(self.max_depth, self.cat_features)\n",
    "                node.grow(gr['X'], gr['y'], depth + 1, potential_features)\n",
    "                self.children.append(node)            \n",
    "            #             print(\"{}X{} < {} gini={}\".format(self.depth*' ',self.split_feature+1, self.split_val, best_split['gini']))\n",
    "            #             print(\"left - Class 0:{},class 1:{}\".format(np.sum(left.iloc[:,-1]==0),np.sum(left.iloc[:,-1]==1)))\n",
    "            #             print(\"right - Class 0:{},class 1:{}\".format(np.sum(right.iloc[:,-1]==0),np.sum(right.iloc[:,-1]==1)))\n",
    "\n",
    "        self.depth = depth\n",
    "        return\n",
    "\n",
    "    def terminate(self, y, depth):\n",
    "        # define leaf node\n",
    "        # most frequent class in the data as class label of this node\n",
    "        self.classification = max(set(y), key=y.count)\n",
    "        self.isleaf = True\n",
    "        self.depth = depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # grow a tree\n",
    "        n = len(X.columns)\n",
    "        X = X.values.tolist()\n",
    "        y = y.values.tolist()\n",
    "        potential_features = np.linspace(0,n-1,n,dtype=np.int32).tolist()\n",
    "        self.grow(X, y, 1, potential_features)\n",
    "        return self\n",
    "\n",
    "    def print_tree(self):\n",
    "        if not self.isleaf:\n",
    "            if self.is_cat_feature:\n",
    "                for i in range(len(self.split_val)):\n",
    "                    print(\"{}X{} = {} \".format(self.depth * ' ', self.split_feature, self.split_val[i]))\n",
    "                    self.children[i].print_tree()\n",
    "            else:\n",
    "                print(\"{}X{} < {} \".format(self.depth * ' ', self.split_feature, self.split_val))\n",
    "                self.children[0].print_tree()\n",
    "                self.children[1].print_tree()\n",
    "        else:\n",
    "            print(\"{}[{}]\".format(self.depth * ' ', self.classification))\n",
    "\n",
    "    def predict_iterate(self, row):\n",
    "\n",
    "        if self.isleaf:\n",
    "            # is leaf node\n",
    "            return self.classification\n",
    "        else:\n",
    "            # not leaf node\n",
    "            if self.is_cat_feature:\n",
    "                # predict categorical feature\n",
    "                for i in range(len(self.split_val)):\n",
    "                    if row[self.split_feature] == self.split_val[i]:\n",
    "                        return self.children[i].predict_iterate(row)\n",
    "                return None\n",
    "            else:\n",
    "                # predict numerical feature\n",
    "                if row[self.split_feature] < self.split_val:\n",
    "                    return self.children[0].predict_iterate(row)\n",
    "                else:\n",
    "                    return self.children[1].predict_iterate(row)\n",
    "\n",
    "    def predict(self, X):\n",
    "        num_rows = X.shape[0]\n",
    "        prediction = []\n",
    "        #         prediction = np.zeros((num_rows,1))\n",
    "        for idx, row in X.iterrows():\n",
    "            prediction.append(self.predict_iterate(row))\n",
    "\n",
    "        return np.array(prediction)\n",
    "\n",
    "    def prune(self, tree):\n",
    "        # prune here\n",
    "        pruned_tree = tree\n",
    "        return pruned_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame([[23.771244718,1.784783929, 'a',0],\n",
    "[11.728571309,55.169761413, 'a',0],\n",
    "[3.678319846,3.81281357, 'a',0],\n",
    "[3.961043357,0.61995032, 'a',0],\n",
    "[2.999208922,2.209014212, 'b',0],\n",
    "[7.497545867,3.162953546, 'b',1],\n",
    "[9.00220326,3.339047188, 'b',1],\n",
    "[7.444542326,0.476683375, 'b',1],\n",
    "[10.12493903,3.234550982, 'b',1],\n",
    "[6.642287351,3.319983761, 'b',1]])\n",
    "# data.columns = ['1','2','3','class']\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split on feature:2 GR=0.6099865470109875\n",
      "terminate at depth=2\n",
      "split on feature:0 GR=0.6500224216483541\n",
      "terminate at depth=3\n",
      "terminate at depth=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.DecisionTreeC45Node at 0x20eda9a3be0>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeC45Node(cat_features=[2], max_depth=10)\n",
    "dt.fit(X=data.iloc[:,:-1],y=data.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.predict(X=data.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X2 = a \n",
      "  [0]\n",
      " X2 = b \n",
      "  X0 < 6.642287351 \n",
      "   [0]\n",
      "   [1]\n"
     ]
    }
   ],
   "source": [
    "dt.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 5]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2,4,5,7]\n",
    "l.remove(7)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
