{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class DecisionTreeC45Node(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, max_depth, cat_features=None):\n",
    "        # property\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "        # constant\n",
    "        self.cat_features = cat_features\n",
    "        # variables\n",
    "        self.children = list()\n",
    "        self.isleaf = False\n",
    "\n",
    "        self.split_val = None\n",
    "        self.split_feature = None\n",
    "        self.is_cat_feature = False\n",
    "        self.classification = None\n",
    "\n",
    "        self.depth = 0\n",
    "\n",
    "    def is_pure(self, y):\n",
    "        # check whether the branch is pure() having same class )\n",
    "\n",
    "        # compare all class label with the class of first row.\n",
    "        #         print(y)\n",
    "        for i in y:\n",
    "            if i != y[0]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def find_split_val(self, X, y, potential_features):\n",
    "        # Find best split value\n",
    "\n",
    "        class_values = list(set(y))     \n",
    "        b_feature, b_value, b_score, b_groups = None, None, None, None\n",
    "        \n",
    "        entropy_parent = self.entropy([y], class_values)\n",
    "        for feature in potential_features:\n",
    "            if feature in self.cat_features:\n",
    "                groups = self.split(feature, None, X, y)\n",
    "                groups_y = list()\n",
    "                split_values = list()\n",
    "                for v,gr in groups.items():\n",
    "                    groups_y.append(gr['y'])\n",
    "                    split_values.append(v)\n",
    "                entropy_children = self.entropy(groups_y, class_values)\n",
    "                split_info = self.splitting_information(groups_y)\n",
    "                if split_info == 0:\n",
    "                    gain_ratio = 0\n",
    "                else:\n",
    "                    gain_ratio = (entropy_parent - entropy_children)\n",
    "#                 print('X{:d} ={} E={:.3f},IG={:.3f},SI={:.3f},GR={:.3f}'.format((feature + 1), \n",
    "#                                                                                 split_values, \n",
    "#                                                                                 entropy_children, \n",
    "#                                                                                 (entropy_parent - entropy_children), \n",
    "#                                                                                 split_info, gain_ratio))\n",
    "                if b_score is None or gain_ratio > b_score:\n",
    "                    b_index, b_value, b_score, b_groups, is_cat_feature = feature, split_values, gain_ratio, groups, True\n",
    "            else:\n",
    "                for row in X:\n",
    "                    groups = self.split(feature, row[feature], X, y)\n",
    "                    groups_y = list()\n",
    "                    for _,gr in groups.items():\n",
    "                        groups_y.append(gr['y'])\n",
    "                    entropy_children = self.entropy(groups_y, class_values)\n",
    "                    split_info = self.splitting_information(groups_y)\n",
    "                    if split_info == 0:\n",
    "                        gain_ratio = 0\n",
    "                    else:\n",
    "                        gain_ratio = (entropy_parent - entropy_children)\n",
    "#                     print('X{:d} ={} E={:.3f},IG={:.3f},SI={:.3f},GR={:.3f}'.format((feature + 1), row[feature], entropy_children, (entropy_parent - entropy_children), split_info, gain_ratio))\n",
    "                    if b_score is None or gain_ratio > b_score:\n",
    "                        b_index, b_value, b_score, b_groups, is_cat_feature = feature, row[feature], gain_ratio, groups, False\n",
    "        return {'index': b_index, 'value': b_value, 'groups': b_groups, 'gain_ratio': b_score, 'is_cat_feature': is_cat_feature}\n",
    "\n",
    "    def split(self, feature, val, X, y):\n",
    "        # split data according to split criteria\n",
    "        groups = dict()\n",
    "        if feature in self.cat_features:\n",
    "            # categorical feature ( multiple branches )\n",
    "            # create branches for each category\n",
    "            for idx, row in enumerate(X):\n",
    "                if row[feature] in groups.keys():\n",
    "                    groups[row[feature]]['X'].append(row)\n",
    "                    groups[row[feature]]['y'].append(y[idx])\n",
    "                else:\n",
    "                    groups[row[feature]] = {'X': [row], 'y': [y[idx]]}\n",
    "        else:\n",
    "            # numerical feature (binary branches)\n",
    "            # data with feature value smaller than val goes to left ( feature < val )\n",
    "            # the rest goes to right\n",
    "            groups['left'] = {'X':list(), 'y':list()}\n",
    "            groups['right'] = {'X':list(), 'y':list()}\n",
    "            for idx, row in enumerate(X):\n",
    "                if row[feature] < val:\n",
    "                    groups['left']['X'].append(row)\n",
    "                    groups['left']['y'].append(y[idx])\n",
    "                else:\n",
    "                    groups['right']['X'].append(row)\n",
    "                    groups['right']['y'].append(y[idx])\n",
    "\n",
    "        return groups\n",
    "\n",
    "    def entropy(self, groups, classes):\n",
    "        # calculte entropy of a split\n",
    "        n_instances = 0\n",
    "        for gr in groups:\n",
    "            n_instances += len(gr)\n",
    "        \n",
    "        entropy = 0.0\n",
    "        for gr in groups:\n",
    "            size = len(gr)\n",
    "            # avoid divide by zero\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "\n",
    "            # score the group based on the score for each class\n",
    "            for class_val in classes:\n",
    "                p = 0.0\n",
    "                for v in gr:\n",
    "                    if v == class_val:\n",
    "                        p += 1\n",
    "                p = p / size\n",
    "                if p > 0:\n",
    "                    score += p * math.log2(p)\n",
    "            # weight the group score by its relative size\n",
    "            entropy += (score) * (size / n_instances)  # *0.5\n",
    "        entropy = -entropy\n",
    "        return entropy\n",
    "\n",
    "    def splitting_information(self, groups):\n",
    "        n_instances = 0\n",
    "        for gr in groups:\n",
    "            n_instances += len(gr)\n",
    "#             print(len(gr))\n",
    "        \n",
    "        splitting_info = 0.0\n",
    "        for gr in groups:\n",
    "            t = len(gr)/n_instances\n",
    "            if t > 0.0:\n",
    "                splitting_info += t * np.log2(t)\n",
    "        splitting_info = -splitting_info\n",
    "        return splitting_info\n",
    "\n",
    "    def grow(self, X, y, depth, potential_features):\n",
    "#         print(\"\\ndepth={}, p_features={}\".format(depth,potential_features))\n",
    "        if self.is_pure(y) or self.max_depth <= depth or len(potential_features) == 0:\n",
    "#             print(\"terminate at depth={}\".format(depth))\n",
    "            self.terminate(y, depth)\n",
    "            return\n",
    "        else:\n",
    "\n",
    "            best_split = self.find_split_val(X, y, potential_features)\n",
    "            self.split_val = best_split['value']\n",
    "            self.split_feature = best_split['index']\n",
    "            self.is_cat_feature = best_split['is_cat_feature']\n",
    "            print(\"split on feature:{} GR={}\".format(self.split_feature, best_split['gain_ratio']))\n",
    "            \n",
    "            if self.is_cat_feature:\n",
    "                potential_features.remove(self.split_feature)\n",
    "            for _, gr in best_split['groups'].items():\n",
    "                node = DecisionTreeC45Node(self.max_depth, self.cat_features)\n",
    "                node.grow(gr['X'], gr['y'], depth + 1, potential_features)\n",
    "                self.children.append(node)            \n",
    "            #             print(\"{}X{} < {} gini={}\".format(self.depth*' ',self.split_feature+1, self.split_val, best_split['gini']))\n",
    "            #             print(\"left - Class 0:{},class 1:{}\".format(np.sum(left.iloc[:,-1]==0),np.sum(left.iloc[:,-1]==1)))\n",
    "            #             print(\"right - Class 0:{},class 1:{}\".format(np.sum(right.iloc[:,-1]==0),np.sum(right.iloc[:,-1]==1)))\n",
    "\n",
    "        self.depth = depth\n",
    "        return\n",
    "\n",
    "    def terminate(self, y, depth):\n",
    "        # define leaf node\n",
    "        # most frequent class in the data as class label of this node\n",
    "        self.classification = max(set(y), key=y.count)\n",
    "        self.isleaf = True\n",
    "        self.depth = depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # grow a tree\n",
    "        n = len(X.columns)\n",
    "        \n",
    "        # convert cat_feature to its index in data X's columns\n",
    "        if self.cat_features is None:\n",
    "            self.cat_features = []\n",
    "        else:\n",
    "            i = 0\n",
    "            cat_features_idx = []\n",
    "            for col in X.columns:\n",
    "                if col in self.cat_features:\n",
    "                    cat_features_idx.append(i)\n",
    "                i += 1\n",
    "            self.cat_features = cat_features_idx\n",
    "        \n",
    "        X = X.values.tolist()\n",
    "        y = y.values.tolist()\n",
    "        potential_features = np.linspace(0,n-1,n,dtype=np.int32).tolist()\n",
    "        self.grow(X, y, 1, potential_features)\n",
    "        return self\n",
    "\n",
    "    def print_tree(self):\n",
    "        if not self.isleaf:\n",
    "            if self.is_cat_feature:\n",
    "                for i in range(len(self.split_val)):\n",
    "                    print(\"{}X{} = {} \".format(self.depth * ' ', self.split_feature, self.split_val[i]))\n",
    "                    self.children[i].print_tree()\n",
    "            else:\n",
    "                print(\"{}X{} < {} \".format(self.depth * ' ', self.split_feature, self.split_val))\n",
    "                self.children[0].print_tree()\n",
    "                self.children[1].print_tree()\n",
    "        else:\n",
    "            print(\"{}[{}]\".format(self.depth * ' ', self.classification))\n",
    "\n",
    "    def predict_iterate(self, row):\n",
    "\n",
    "        if self.isleaf:\n",
    "            # is leaf node\n",
    "            return self.classification\n",
    "        else:\n",
    "            # not leaf node\n",
    "            if self.is_cat_feature:\n",
    "                # predict categorical feature\n",
    "                for i in range(len(self.split_val)):\n",
    "                    if row[self.split_feature] == self.split_val[i]:\n",
    "                        return self.children[i].predict_iterate(row)\n",
    "                return None\n",
    "            else:\n",
    "                # predict numerical feature\n",
    "                if row[self.split_feature] < self.split_val:\n",
    "                    return self.children[0].predict_iterate(row)\n",
    "                else:\n",
    "                    return self.children[1].predict_iterate(row)\n",
    "\n",
    "    def predict(self, X):\n",
    "        num_rows = X.shape[0]\n",
    "        prediction = []\n",
    "        #         prediction = np.zeros((num_rows,1))\n",
    "        for idx, row in X.iterrows():\n",
    "            prediction.append(self.predict_iterate(row))\n",
    "\n",
    "        return np.array(prediction)\n",
    "\n",
    "    def prune(self, tree):\n",
    "        # prune here\n",
    "        pruned_tree = tree\n",
    "        return pruned_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame([[23.771244718,1.784783929, 'a',0],\n",
    "[11.728571309,55.169761413, 'a',0],\n",
    "[3.678319846,3.81281357, 'a',0],\n",
    "[3.961043357,0.61995032, 'a',0],\n",
    "[2.999208922,2.209014212, 'b',0],\n",
    "[7.497545867,3.162953546, 'b',1],\n",
    "[9.00220326,3.339047188, 'b',1],\n",
    "[7.444542326,0.476683375, 'b',1],\n",
    "[10.12493903,3.234550982, 'b',1],\n",
    "[6.642287351,3.319983761, 'b',1]])\n",
    "# data.columns = ['1','2','3','class']\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split on feature:2 GR=0.6099865470109875\n",
      "split on feature:0 GR=0.6500224216483541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeC45Node(cat_features=[2], max_depth=10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeC45Node(cat_features=[2], max_depth=10)\n",
    "dt.fit(X=data.iloc[:,:-1],y=data.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.predict(X=data.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X2 = a \n",
      "  [0]\n",
      " X2 = b \n",
      "  X0 < 6.642287351 \n",
      "   [0]\n",
      "   [1]\n"
     ]
    }
   ],
   "source": [
    "dt.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on CKD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'age'</th>\n",
       "      <th>'bp'</th>\n",
       "      <th>'sg'</th>\n",
       "      <th>'al'</th>\n",
       "      <th>'su'</th>\n",
       "      <th>'rbc'</th>\n",
       "      <th>'pc'</th>\n",
       "      <th>'pcc'</th>\n",
       "      <th>'ba'</th>\n",
       "      <th>'bgr'</th>\n",
       "      <th>...</th>\n",
       "      <th>'pcv'</th>\n",
       "      <th>'wbcc'</th>\n",
       "      <th>'rbcc'</th>\n",
       "      <th>'htn'</th>\n",
       "      <th>'dm'</th>\n",
       "      <th>'cad'</th>\n",
       "      <th>'appet'</th>\n",
       "      <th>'pe'</th>\n",
       "      <th>'ane'</th>\n",
       "      <th>'class'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   'age'  'bp'   'sg'  'al'  'su'   'rbc'      'pc'       'pcc'        'ba'  \\\n",
       "0   48.0  80.0  1.020   1.0   0.0     NaN    normal  notpresent  notpresent   \n",
       "1    7.0  50.0  1.020   4.0   0.0     NaN    normal  notpresent  notpresent   \n",
       "2   62.0  80.0  1.010   2.0   3.0  normal    normal  notpresent  notpresent   \n",
       "3   48.0  70.0  1.005   4.0   0.0  normal  abnormal     present  notpresent   \n",
       "4   51.0  80.0  1.010   2.0   0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "   'bgr'  ...  'pcv'  'wbcc'  'rbcc'  'htn'  'dm'  'cad'  'appet'  'pe' 'ane'  \\\n",
       "0  121.0  ...   44.0  7800.0     5.2    yes   yes     no     good    no    no   \n",
       "1    NaN  ...   38.0  6000.0     NaN     no    no     no     good    no    no   \n",
       "2  423.0  ...   31.0  7500.0     NaN     no   yes     no     poor    no   yes   \n",
       "3  117.0  ...   32.0  6700.0     3.9    yes    no     no     poor   yes   yes   \n",
       "4  106.0  ...   35.0  7300.0     4.6     no    no     no     good    no    no   \n",
       "\n",
       "  'class'  \n",
       "0     ckd  \n",
       "1     ckd  \n",
       "2     ckd  \n",
       "3     ckd  \n",
       "4     ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset/chronic_kidney_disease_full.csv\", na_values=['?','\\t?'])\n",
    "print(df.shape)\n",
    "df = df.drop(columns = ['id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill NA values with most frequent values in the column\n",
    "df = df.fillna(df.mode().iloc[0])\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical columns: ['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n",
      "\n",
      "categorical column index: [5, 6, 7, 8, 18, 19, 20, 21, 22, 23]\n",
      "\n",
      "numerical columns: ['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wbcc', 'rbcc']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_col = []\n",
    "for col in df.columns:\n",
    "    col = col.replace(\"'\",'')\n",
    "    new_col.append(col)\n",
    "df.columns = new_col\n",
    "\n",
    "str_cols = []\n",
    "str_cols_index = []\n",
    "num_cols = []\n",
    "i = 0\n",
    "for col in df.drop(columns = 'class').columns:\n",
    "    if df[col].dtype != np.int64 and df[col].dtype != np.float64:\n",
    "        str_cols.append(col)\n",
    "        str_cols_index.append(i)\n",
    "    else:\n",
    "        num_cols.append(col)\n",
    "    i += 1\n",
    "    \n",
    "print(\"categorical columns: {}\\n\".format(str_cols))\n",
    "print(\"categorical column index: {}\\n\".format(str_cols_index))\n",
    "print(\"numerical columns: {}\\n\".format(num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split on feature:11 GR=0.5099416058315251\n",
      "split on feature:2 GR=0.5863755004101161\n",
      "split on feature:14 GR=0.2145075136979618\n",
      "split on feature:1 GR=0.05943853804639755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeC45Node(cat_features=[5, 6, 7, 8, 18, 19, 20, 21, 22, 23],\n",
       "          max_depth=5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeC45Node(cat_features=str_cols, max_depth=5)\n",
    "# %prun dt.train(X=X_train,y=y_train, cat_features=str_cols, max_depth=5)\n",
    "dt.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9772727272727273\n"
     ]
    }
   ],
   "source": [
    "pred = dt.predict(X_test)\n",
    "\n",
    "print(np.sum(pred == y_test)/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " X11 < 1.3 \n",
      "  X2 < 1.02 \n",
      "   [ckd]\n",
      "   X14 < 13.0 \n",
      "    [ckd]\n",
      "    X1 < 90.0 \n",
      "     [notckd]\n",
      "     [ckd]\n",
      "  [ckd]\n"
     ]
    }
   ],
   "source": [
    "dt.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 7, 8, 18, 19, 20, 21, 22, 23]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
